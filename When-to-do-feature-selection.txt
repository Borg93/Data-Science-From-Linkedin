
Kyle McKiou
Kyle McKiou

Do you do feature selection when building your 
#machinelearning models?

ðŸ’¡ When should you reduce the number of features used by your model?

Some instances when features selection is necessary:
â€¢ When there is strong collinearity between features
â€¢ There are an overwhelming number of features
â€¢ The is not enough computational power to process all features
â€¢ The algorithm forces the model to use all features, even when they are not useful (most often in parametric or linear models)
â€¢ When you wish to make the model simpler for any reason, e.g. easier to explain, less computational power needed, etc

ðŸ’¡ When is feature selection unnecessary?

Some instances when feature selection is not necessary:
â€¢ There are relatively few features
â€¢ All features contain useful and important signal
â€¢ There is no collinearity between features
â€¢ The model will automatically select the most useful features
â€¢ The computing resources can handle processing all of the features
â€¢ Thoroughly explaining the model to a non-technical audience is not critical
